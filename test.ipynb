import sys
print(sys.version)

### Load modules

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from mpl_toolkits.mplot3d import Axes3D
import ipywidgets as widgets
import pyvista as pv
from itkwidgets import view
print("Pandas version  : ",pd.__version__)
print("PyVista version : ",pv.__version__)
print("NumPy version   : ",np.__version__)
%matplotlib widget
pv.rcParams['use_ipyvtk'] = True
pd.set_option('precision', 6)

#%cat 'data/synth.dat'

#%pip freeze  > requirements.txt

### 1. Read raw datas from tecplot

df = pd.read_csv(filepath_or_buffer=r'data/input_data/synth.dat',sep='\t',skiprows=10,
                 names=["X","Y","Z","Layer1","Layer2","Layer3","Layer4","Layer5"],dtype=np.float64)

layers=list(df.columns[3:]) # X,Y,Z
df.head()

### 2. Filtering datas

#### 2.1 Function for filtering / sorting and merging layers from raw datas

def mask_df(df,formation):
    df_f = df.copy()
    df_f = df[df[formation]==1]
    l=layers.copy() 
    l.remove(formation)
    df_f=df_f.drop(columns=l)
    df_f.rename(columns={formation: 'formation'}, inplace=True)
    df_f=df_f.assign(formation=str(formation))
    return df_f

def sort_df(df,formation):
    df_l = mask_df(df,formation)
    groups = df_l.groupby(['X','Y'])
    df_sort = groups.max()
    df_sort.reset_index(inplace=True)
    return df_sort

def grad_df(df,normals,formation):
    df_grad = sort_df(df,formation)
    df_grad.insert(loc=3, column = 'G_x', value=normals[:,0])
    df_grad.insert(loc=4, column = 'G_y', value=normals[:,1])
    df_grad.insert(loc=5, column = 'G_z', value=normals[:,2])
    return df_grad

#### 2.2 Plot 3d raw data

sns.set(style = "darkgrid")
fig = plt.figure()
ax = fig.add_subplot(111, projection = '3d')
for layer in layers :
    df_l = mask_df(df,layer)
    x,y,z = [df_l['X'], df_l['Y'], df_l['Z']]
    ax.scatter(x, y, z,s=30,depthshade=True)
plt.grid(b=True,axis='both')
plt.show(True)

#### 2.3 And the Vasarely's plot

import matplotlib.pyplot as plt
def plot_elevation_map(layer):
    df_sort = sort_df(df,layer)
    pts_x,pts_y,pts_z = [df_sort.X.to_numpy(),df_sort.Y.to_numpy(),df_sort.Z.to_numpy()]
    points = np.c_[pts_x, pts_y, pts_z]

    plt.figure(figsize=(5, 5))
    plt.scatter(points[:, 0], points[:, 1], c=points[:, 2],s=100,marker="o",cmap="viridis")
    plt.axis("image")
    plt.colorbar()
    plt.xlabel("X Coordinate")
    plt.ylabel("Y Coordinate")
    plt.show()
widgets.interact(plot_elevation_map,
                layer=widgets.Combobox(description='Layer',options=["Layer1", "Layer2", "Layer3", "Layer4", "Layer5"], value="Layer1"))

#### 2.4 Set vertical exageration

ve_txt = widgets.FloatText(description='Z vert. ex.',value=100)
ve_slider = widgets.IntSlider(min=10,max=1000,step=10,value=100)
display(ve_txt,ve_slider)

ve = widgets.jslink((ve_txt, 'value'), (ve_slider, 'value'))

#### 2.5 Concatenate all layers point positions in a surface dataFrame

df_all_surf = pd.concat([sort_df(df,layer) for layer in layers],sort=True)
np.shape(df_all_surf)
df_all_surf.tail()

#### 2.6 Compute Azimuth, dip angles from pole gradient vectors (normals definition)

def calculate_orientations(df, idx=None):
        if idx is None:
            pol = 1
            df.insert(loc=6,column = 'azimuth',value = np.rad2deg(np.nan_to_num(np.arctan2(df["G_x"] / pol,
                                                                                           df["G_y"] / pol))))
            df.insert(loc=7,column = 'dip', value = np.rad2deg(np.nan_to_num(np.arccos(df["G_z"] / pol))))
            df.insert(loc=8,column = 'polarity',value  = pol)
            # mask
            df["azimuth"][df["azimuth"] < 0] += 360  # shift values from [-pi, 0] to [pi,2*pi]
            df["azimuth"][df["dip"] < 0.001] = 0  # because if dip is zero azimuth is undefined
        else:
            df.loc[idx, 'polarity'] = 1
            df.loc[idx, "dip"] = np.rad2deg(np.nan_to_num(np.arccos(df.loc[idx, "G_z"] /
                                                                    df.loc[idx, "polarity"])))
            df.loc[idx, "azimuth"] = np.rad2deg(np.nan_to_num(
                np.arctan2(df.loc[idx, "G_x"] / df.loc[idx, "polarity"],
                           df.loc[idx, "G_y"] / df.loc[idx, "polarity"])))
            df["azimuth"][df["azimuth"] < 0] += 360  # shift values from [-pi, 0] to [pi,2*pi]
            df["azimuth"][df["dip"] < 0.001] = 0  # because if dip is zero azimuth is undefined
        return df

#### 2.7 Compute pole gradients ```G_x, G_y, G_z``` as normal vectors from a surface layer (```delaunay_2d```)

##### 2.7.1 Plot layers and normals

def plot_layers_orientation(ve,fact_n,is_l1,is_l2,is_l3,is_l4,is_l5):
    clr = ['b','orange','g','r','m']
    id=0
    is_layer = [is_l1,is_l2,is_l3,is_l4,is_l5]
    p.remove_legend()
    p.clear()
    df_all_grad = pd.DataFrame(columns = ['X','Y','Z','G_x', 'G_y', 'G_z','formation'])
    for layer in layers:
        if is_layer[layers.index(layer)] :
            df_sort = sort_df(df,layer)

            pts_x,pts_y,pts_z = [df_sort.X.to_numpy(),df_sort.Y.to_numpy(),df_sort.Z.to_numpy()]
            points = np.c_[pts_x, pts_y, ve*pts_z]
            print(np.shape(points))
            cloud = pv.PolyData(points)
            surf = cloud.delaunay_2d(tol=1e-5,progress_bar=True,offset=1e-5)
            surf.compute_normals(cell_normals=False, point_normals=True,inplace=True)  # this activates the normals as well
            normals = surf['Normals']
            df_all_grad=df_all_grad.append(grad_df(df,normals,layer),ignore_index=True)
            # plot 
            arrows = surf.glyph(scale="Normals", orient="Normals", tolerance=0.01,factor=fact_n)
            mesh.points = points
            glyph_act = p.add_mesh(arrows, color="c",point_size=10)
            surf_act = p.add_mesh(surf,color=clr[id],smooth_shading=True,label=layer,show_edges=True,opacity=1,lighting=True)
            id +=1
    p.show_grid()
    p.add_axes()
    p.add_legend()
    p.show() 

mesh = pv.UnstructuredGrid()
p = pv.Plotter()

widgets.interact(plot_layers_orientation,
                 ve=widgets.IntSlider(description='Z vert. ex.',min=10,max=1000,step=10,value=ve_txt.value),
                 fact_n=widgets.IntSlider(description='Glyph ex.',min=10,max=2000,step=100,value=900),
                 is_l1=widgets.Checkbox(description='Layer 1',value=True),
                 is_l2=widgets.Checkbox(description='Layer 2',value=False),
                 is_l3=widgets.Checkbox(description='Layer 3',value=False),
                 is_l4=widgets.Checkbox(description='Layer 4',value=False),
                 is_l5=widgets.Checkbox(description='Layer 5',value=False)) 

##### 2.7.2 Load orientation dataFrame for orientation vectors

print('Z exageration value : ',ve_txt.value)
df_all_grad = pd.DataFrame(columns = ['X','Y','Z','G_x', 'G_y', 'G_z','formation'])
for layer in layers:
    df_sort = sort_df(df,layer)
    pts_x,pts_y,pts_z = [df_sort.X.to_numpy(),df_sort.Y.to_numpy(),df_sort.Z.to_numpy()]
    points = np.c_[pts_x, pts_y, ve_txt.value*pts_z]
    print('Surface point for ',layer,' : ',np.shape(points))
    cloud = pv.PolyData(points)
    surf = cloud.delaunay_2d(tol=1e-5,offset=1e-5)
    surf.compute_normals(cell_normals=False, point_normals=True,inplace=True)  # this activates the normals as well
    normals = surf['Normals']
    df_all_grad=df_all_grad.append(grad_df(df,normals,layer),ignore_index=True)
df_all = calculate_orientations(df_all_grad) # insert azimuth, dip, polarity from normals calculation

### 3. Save surface dataFrame in ```csv``` format

def save_surface_in_csv(nbin,rand,is_l1,is_l2,is_l3,is_l4,is_l5):
    df_surf_mask = pd.DataFrame(columns = ['X','Y','Z','formation'])
    df_surf = df_all_surf.sample(n=nbin,random_state=rand) # bins
    df_surf['Z']=df_surf['Z']*ve_txt.value # vertical exageration
    if is_l1:
        df_surf_mask = df_surf_mask.append(df_surf[df_surf['formation']=='Layer1'])
    if is_l2:
        df_surf_mask = df_surf_mask.append(df_surf[df_surf['formation']=='Layer2'])
    if is_l3:
        df_surf_mask = df_surf_mask.append(df_surf[df_surf['formation']=='Layer3'])
    if is_l4:
        df_surf_mask = df_surf_mask.append(df_surf[df_surf['formation']=='Layer4'])
    if is_l5:
        df_surf_mask = df_surf_mask.append(df_surf[df_surf['formation']=='Layer5'])
    df_surf_mask.to_csv(r'data/df_synth_surf.csv', sep=',', encoding='utf-8',index=False)
    print(df_surf_mask.head())
    print('... surface file saved')
    
widgets.interact(save_surface_in_csv,
                 nbin=widgets.IntSlider(description='Number of bins',min=10,max=len(sort_df(df,"Layer1")),step=10,value=50),
                 rand=widgets.IntSlider(description='random state number',min=1,max=10,step=1,value=2),
                 is_l1=widgets.Checkbox(description='Layer 1',value=True),
                 is_l2=widgets.Checkbox(description='Layer 2',value=True),
                 is_l3=widgets.Checkbox(description='Layer 3',value=True),
                 is_l4=widgets.Checkbox(description='Layer 4',value=True),
                 is_l5=widgets.Checkbox(description='Layer 5',value=False))

#### 4. Save orientation dataFrame in ```csv``` format

def save_orientation_in_csv(pole_gradient,azimuth_angle,nbin,rand,is_l1,is_l2,is_l3,is_l4,is_l5):
    df_grad_mask = pd.DataFrame(columns = ['X','Y','Z','G_x', 'G_y', 'G_z','azimuth', 'dip', 'polarity','formation'])
    df_grad = df_all_grad.sample(n=nbin,random_state=rand) # bins
    if (not pole_gradient):
        df_grad.drop(columns = ['G_x', 'G_y', 'G_z'],inplace = True)
        df_grad_mask.drop(columns = ['G_x', 'G_y', 'G_z'],inplace = True)
    if (not azimuth_angle):
        df_grad.drop(columns = ['azimuth', 'dip','polarity'],inplace = True)
        df_grad_mask.drop(columns = ['azimuth', 'dip','polarity'],inplace = True)
    df_grad['Z']=df_grad['Z']*ve_txt.value # vertical exageration
    if is_l1:
        df_grad_mask = df_grad_mask.append(df_grad[df_grad['formation']=='Layer1'])
    if is_l2:
        df_grad_mask = df_grad_mask.append(df_grad[df_grad['formation']=='Layer2'])
    if is_l3:
        df_grad_mask = df_grad_mask.append(df_grad[df_grad['formation']=='Layer3'])
    if is_l4:
        df_grad_mask = df_grad_mask.append(df_grad[df_grad['formation']=='Layer4'])
    if is_l5:
        df_grad_mask = df_grad_mask.append(df_grad[df_grad['formation']=='Layer5'])
    df_grad_mask.to_csv(r'data/df_synth_orient.csv', sep=',', encoding='utf-8',index=False)
    df_grad_mask.head()
    print('... orientations file saved')
    
widgets.interact(save_orientation_in_csv,
                 pole_gradient=widgets.Checkbox(description='Gradient',value=True),
                 azimuth_angle=widgets.Checkbox(description='Azimuth',value=True),
                 nbin=widgets.IntSlider(description='Number of bins',min=10,max=len(sort_df(df,"Layer1")),step=10,value=50),
                 rand=widgets.IntSlider(description='random state number',min=1,max=10,step=1,value=2),
                 is_l1=widgets.Checkbox(description='Layer 1',value=True),
                 is_l2=widgets.Checkbox(description='Layer 2',value=True),
                 is_l3=widgets.Checkbox(description='Layer 3',value=True),
                 is_l4=widgets.Checkbox(description='Layer 4',value=True),
                 is_l5=widgets.Checkbox(description='Layer 5',value=False))

### 5. Use GemPy and theano interpolation

import gempy as gp
import os
os.environ["THEANO_FLAGS"] = "mode=FAST_RUN,device=cpu"

#### 5.1 Set the resolution in ```x,y,z```

res_x = widgets.IntSlider(description='res x',min=20,max=100,step=10,value=20)
res_y = widgets.IntSlider(description='res y',min=20,max=100,step=10,value=20)
res_z = widgets.IntSlider(description='res z',min=20,max=100,step=10,value=20)
ui = widgets.VBox([res_x, res_y, res_z])
def f(res_x, res_y, res_z):
    print('resolution : [',res_x, res_y, res_z,']')
out = widgets.interactive_output(f, {'res_x': res_x, 'res_y': res_y, 'res_z': res_z})
display(ui, out)

geo_data = gp.create_data('synth_model',
                           extent=[0, 10000, 0, 10000, 0, 2500],
                           resolution=[res_x.value,res_y.value,res_z.value],
                           path_i ="data/df_synth_surf.csv",
                           path_o ="data/df_synth_orient.csv",default_value=True)
#gp.set_orientation_from_surface_points(geo_data,[0,1,2])
gp.get_data(geo_data,'orientations').describe()

#### 5.2 Load a random topography

geo_data.surfaces
geo_data.set_topography(source='random')

#### 5.3 Declare series and surface order

gp.map_stack_to_surfaces(geo_data, {"Strat_Series": ("Layer4","Layer3","Layer2","Layer1"),
                                    "Basement Series":"basement"},
                                   remove_unused_series=False)
gp.map_series_to_surfaces(geo_data, {"Strat_series":('basement','Layer4','Layer3','Layer2','Layer1')},remove_unused_series=False)
geo_data.surfaces.colors.change_colors({'Layer1': '#015482', 'Layer2': '#e5350f', 'Layer3': '#728f02','Layer4': '#9f0052',
                                        'basement': '#443988'})
geo_data.surfaces

#### 5.4 Interpolate and plot 3d gempy model

interp_data = gp.set_interpolator(geo_data, compile_theano=True,theano_optimizer='fast_compile')

sol = gp.compute_model(geo_data,set_solutions=True, compute_mesh=True)

sol.lith_block

sol.grid

def plot_cross_section(cell,layer,dir):
    gp.plot_2d(geo_data, cell_number=cell, series_n=layer,direction=dir,ve=2,
               show_data=True,
               show_boundaries=True,
               show_results=True,
               show_topography=True,kwargs_regular_grid={'cmap': 'viridis', 'norm':None})
    #plt.show()
widgets.interact(plot_cross_section,
                 cell=widgets.IntSlider(description='slice on x/y :',min=0,max=res_x.value-1,step=1,value=10),
                 layer=[('Layer1', 0), ('Layer2', 1), ('Layer3', 2), ('Layer4', 3), ('Layer5', 4)],
                 dir=['x','y'])

#gp.plot_3d(geo_data, plotter_type='background',ve=1,show_topography=True,show_data=True,show_surfaces=True,show_results=True,show_lith=True)

#gp.plot.plot_interactive_3d(geo_data)

### 5.4 Save model

# Simple export to VTK:
def export_to_vtk(sol,filename):
    import pyevtk
    print('regular grid:\t', sol.grid.regular_grid.resolution, '\t', sol.grid.regular_grid.extent.astype(int))

    #Export whole, uncropped lith_block
    #Get coordinate info from grid & create VTK cells info:
    xmin = sol.grid.regular_grid.extent[0]
    xmax = sol.grid.regular_grid.extent[1]
    xres = sol.grid.regular_grid.resolution[0]
    dx   = (xmax-xmin)/xres                       #pixel width
    xvals = np.arange(xmin,xmax+dx,dx)

    ymin = sol.grid.regular_grid.extent[2]
    ymax = sol.grid.regular_grid.extent[3]
    yres = sol.grid.regular_grid.resolution[1]
    dy   = (ymax-ymin)/yres
    yvals = np.arange(ymin,ymax+dy,dy)

    zmin = sol.grid.regular_grid.extent[4]
    zmax = sol.grid.regular_grid.extent[5]
    zres = sol.grid.regular_grid.resolution[2]
    dz   = (zmax-zmin)/zres
    zvals = np.arange(zmin,zmax+dz,dz)

    print('x:', xmin,xmax,xres,dx)
    print('y:', ymin,ymax,yres,dy)
    print('z:', zmin,zmax,zres,dz)

    g = sol.lith_block.copy()            #make a copy to avoid messing up original
    g = np.reshape(g, (xres,yres,zres))  #reshape lith block to 3D
    print('shape of array to export:', g.shape)
    plt.imshow(g[:,:,zres-1])
    print( )
    path = r'./data/output_model/'+str(filename)  #set file path to save to (should have no extension)
    pyevtk.hl.gridToVTK(path, xvals, yvals, zvals, cellData={'data': g}) #PYthon Export to VTK

export_to_vtk(sol,'synth_model')

gp.save_model(geo_data)
#np.save('Layer1_ver', geo_data.solutions.vertices) # numpy binary export .npy
#np.save('Layer1_edges', geo_data.solutions.edges)
